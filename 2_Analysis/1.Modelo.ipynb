{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Librerias ...\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import ensemble\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model.ridge import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "import warnings\n",
    "import math\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lectura de datos archivo CSV\n",
    "df = pd.read_csv('C:\\\\v\\\\1_DataAdquisition\\\\salida.csv', header=0, index_col=0)",
    "# Nota: El path del archivo es ABSOLUTO y deberia de apuntar a donde se encuentra el archivo generado el el paso 1.DataAdquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Check Data\n",
    "\n",
    "Aqui partiendo del Jupyter Notebook 0.Analisis_Exploratorio_Datos vamos aplicar algunas conclusiones tanto de limpieza como de validacion de datos, para asi detectar valores anómalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminacion de filas repetidas\n",
    "df = df.groupby(['Caso X', 'D','L','Beta','Velocidad','Angulo','A','B','Q', 'Reynolds','TotalAreaInlet', 'P']).size().reset_index()\n",
    "\n",
    "# Eliminacion de filas que tienen un coeficiente de Reynols muy negativo. Posiblemente a simulaciones que han producido un error.\n",
    "# xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "\n",
    "# Eliminacion de columnas A y B, por ser variables que son de salida de la simulacion\n",
    "X = df.drop(['A','B'], axis=1, inplace=True)\n",
    "\n",
    "# Eliminacion de la variable categorica Caso X, al ser una variable que no aporta nada, ya que tan solo define dado un caso\n",
    "# a un conjunto de caracteristicas geometricas D,L,Beta\n",
    "X = df.drop(['Caso X'],axis=1, inplace=True)\n",
    "\n",
    "# Eliminacion de la columna Reynolds, al saber que existe una relacion y Q\n",
    "X = df.drop(['Reynolds'], axis=1, inplace=True)\n",
    "\n",
    "# Eliminacion de la columna TotalAreaInlet, al saber que existe una relacion y Q\n",
    "X = df.drop(['TotalAreaInlet'], axis=1, inplace=True)\n",
    "\n",
    "# Eliminacion de la columna Velocidad, al saber que existe una relacion y Q\n",
    "X = df.drop(['Velocidad'], axis=1, inplace=True)\n",
    "\n",
    "# Featuring Engineering\n",
    "df['Q'] = abs(df['Q'])\n",
    "df['QQ'] = df['Q'] * df['Q']\n",
    "df['QPlusQQ'] = df['Q'] + (df['Q'] * df['Q'])\n",
    "\n",
    "# Por supuesto quitamos como variable de entrada la variable a PREDECIR, pero no inplace porque luego se lo asignaremos a Y\n",
    "X = df.drop(['P'], axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>L</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Angulo</th>\n",
       "      <th>Q</th>\n",
       "      <th>P</th>\n",
       "      <th>0</th>\n",
       "      <th>QQ</th>\n",
       "      <th>QPlusQQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>19.252066</td>\n",
       "      <td>1</td>\n",
       "      <td>4.095315e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>24.926916</td>\n",
       "      <td>1</td>\n",
       "      <td>4.112122e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>82.646603</td>\n",
       "      <td>1</td>\n",
       "      <td>4.124986e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>30.105155</td>\n",
       "      <td>1</td>\n",
       "      <td>4.133462e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-120</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>116.412337</td>\n",
       "      <td>1</td>\n",
       "      <td>4.137941e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>82.088580</td>\n",
       "      <td>2</td>\n",
       "      <td>4.128348e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>119.307336</td>\n",
       "      <td>1</td>\n",
       "      <td>4.430531e-09</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>27.382207</td>\n",
       "      <td>1</td>\n",
       "      <td>7.291549e-09</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>40.487631</td>\n",
       "      <td>1</td>\n",
       "      <td>7.297716e-09</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>128.531086</td>\n",
       "      <td>1</td>\n",
       "      <td>7.306977e-09</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-170</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>41.901642</td>\n",
       "      <td>1</td>\n",
       "      <td>7.318792e-09</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>233.041292</td>\n",
       "      <td>1</td>\n",
       "      <td>7.857956e-09</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>36.227969</td>\n",
       "      <td>2</td>\n",
       "      <td>1.139215e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>51.421813</td>\n",
       "      <td>1</td>\n",
       "      <td>1.140645e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>193.705257</td>\n",
       "      <td>1</td>\n",
       "      <td>1.141618e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-170</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>56.822894</td>\n",
       "      <td>1</td>\n",
       "      <td>1.143681e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>213.989580</td>\n",
       "      <td>1</td>\n",
       "      <td>1.145132e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>283.501946</td>\n",
       "      <td>1</td>\n",
       "      <td>1.228312e-08</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>119.507168</td>\n",
       "      <td>1</td>\n",
       "      <td>4.081319e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>19.334154</td>\n",
       "      <td>1</td>\n",
       "      <td>4.100363e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>26.701303</td>\n",
       "      <td>1</td>\n",
       "      <td>4.119728e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>27.946233</td>\n",
       "      <td>2</td>\n",
       "      <td>4.130711e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-120</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>125.712072</td>\n",
       "      <td>3</td>\n",
       "      <td>4.136057e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>92.636307</td>\n",
       "      <td>2</td>\n",
       "      <td>4.133374e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>74.348635</td>\n",
       "      <td>1</td>\n",
       "      <td>4.142113e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>27.310798</td>\n",
       "      <td>1</td>\n",
       "      <td>7.289389e-09</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>41.751336</td>\n",
       "      <td>1</td>\n",
       "      <td>7.315196e-09</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>120.123256</td>\n",
       "      <td>1</td>\n",
       "      <td>7.333350e-09</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>230.927125</td>\n",
       "      <td>1</td>\n",
       "      <td>7.879005e-09</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>163.499632</td>\n",
       "      <td>1</td>\n",
       "      <td>1.133312e-08</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>32.897147</td>\n",
       "      <td>1</td>\n",
       "      <td>7.870350e-09</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-120</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>353.422987</td>\n",
       "      <td>1</td>\n",
       "      <td>1.138856e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>341.755694</td>\n",
       "      <td>1</td>\n",
       "      <td>1.141850e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>64.353819</td>\n",
       "      <td>1</td>\n",
       "      <td>1.145992e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>232.870333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.150845e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>44.207213</td>\n",
       "      <td>1</td>\n",
       "      <td>1.229666e-08</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-120</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>125.640429</td>\n",
       "      <td>1</td>\n",
       "      <td>4.130309e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>32.503984</td>\n",
       "      <td>3</td>\n",
       "      <td>4.132255e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>79.623473</td>\n",
       "      <td>1</td>\n",
       "      <td>4.134416e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>24.772510</td>\n",
       "      <td>1</td>\n",
       "      <td>4.149972e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>73.671811</td>\n",
       "      <td>3</td>\n",
       "      <td>4.128926e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>31.053093</td>\n",
       "      <td>1</td>\n",
       "      <td>4.145104e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>59.630639</td>\n",
       "      <td>1</td>\n",
       "      <td>7.338233e-09</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>33.582872</td>\n",
       "      <td>1</td>\n",
       "      <td>7.855723e-09</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-120</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>348.252254</td>\n",
       "      <td>1</td>\n",
       "      <td>1.145096e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>193.133414</td>\n",
       "      <td>1</td>\n",
       "      <td>1.145959e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>83.673936</td>\n",
       "      <td>1</td>\n",
       "      <td>1.148272e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>44.107214</td>\n",
       "      <td>1</td>\n",
       "      <td>1.227780e-08</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>88.547375</td>\n",
       "      <td>1</td>\n",
       "      <td>4.118679e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>34.896203</td>\n",
       "      <td>3</td>\n",
       "      <td>4.117735e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>22.221646</td>\n",
       "      <td>1</td>\n",
       "      <td>4.125849e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>65.665795</td>\n",
       "      <td>3</td>\n",
       "      <td>4.133758e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>33.332105</td>\n",
       "      <td>1</td>\n",
       "      <td>4.131471e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-120</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>139.132259</td>\n",
       "      <td>1</td>\n",
       "      <td>4.148286e-09</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>50.836832</td>\n",
       "      <td>1</td>\n",
       "      <td>7.313975e-09</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>31.978572</td>\n",
       "      <td>1</td>\n",
       "      <td>7.859611e-09</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>164.762425</td>\n",
       "      <td>1</td>\n",
       "      <td>1.141061e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>68.033342</td>\n",
       "      <td>1</td>\n",
       "      <td>1.146165e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-120</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>325.643063</td>\n",
       "      <td>1</td>\n",
       "      <td>1.150694e-08</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>42.002103</td>\n",
       "      <td>1</td>\n",
       "      <td>1.228353e-08</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         D    L  Beta  Angulo         Q           P  0            QQ   QPlusQQ\n",
       "0    0.040  0.9   0.2       0  0.000064   19.252066  1  4.095315e-09  0.000064\n",
       "1    0.040  0.9   0.2     170  0.000064   24.926916  1  4.112122e-09  0.000064\n",
       "2    0.040  0.9   0.2    -145  0.000064   82.646603  1  4.124986e-09  0.000064\n",
       "3    0.040  0.9   0.2    -170  0.000064   30.105155  1  4.133462e-09  0.000064\n",
       "4    0.040  0.9   0.2    -120  0.000064  116.412337  1  4.137941e-09  0.000064\n",
       "5    0.040  0.9   0.2     145  0.000064   82.088580  2  4.128348e-09  0.000064\n",
       "6    0.040  0.9   0.2     120  0.000067  119.307336  1  4.430531e-09  0.000067\n",
       "7    0.040  0.9   0.2       0  0.000085   27.382207  1  7.291549e-09  0.000085\n",
       "8    0.040  0.9   0.2     170  0.000085   40.487631  1  7.297716e-09  0.000085\n",
       "9    0.040  0.9   0.2    -145  0.000085  128.531086  1  7.306977e-09  0.000085\n",
       "10   0.040  0.9   0.2    -170  0.000086   41.901642  1  7.318792e-09  0.000086\n",
       "11   0.040  0.9   0.2     120  0.000089  233.041292  1  7.857956e-09  0.000089\n",
       "12   0.040  0.9   0.2       0  0.000107   36.227969  2  1.139215e-08  0.000107\n",
       "13   0.040  0.9   0.2     170  0.000107   51.421813  1  1.140645e-08  0.000107\n",
       "14   0.040  0.9   0.2    -145  0.000107  193.705257  1  1.141618e-08  0.000107\n",
       "15   0.040  0.9   0.2    -170  0.000107   56.822894  1  1.143681e-08  0.000107\n",
       "16   0.040  0.9   0.2     145  0.000107  213.989580  1  1.145132e-08  0.000107\n",
       "17   0.040  0.9   0.2     120  0.000111  283.501946  1  1.228312e-08  0.000111\n",
       "18   0.055  0.9   0.2     120  0.000064  119.507168  1  4.081319e-09  0.000064\n",
       "19   0.055  0.9   0.2       0  0.000064   19.334154  1  4.100363e-09  0.000064\n",
       "20   0.055  0.9   0.2    -170  0.000064   26.701303  1  4.119728e-09  0.000064\n",
       "21   0.055  0.9   0.2     170  0.000064   27.946233  2  4.130711e-09  0.000064\n",
       "22   0.055  0.9   0.2    -120  0.000064  125.712072  3  4.136057e-09  0.000064\n",
       "23   0.055  0.9   0.2     145  0.000064   92.636307  2  4.133374e-09  0.000064\n",
       "24   0.055  0.9   0.2    -145  0.000064   74.348635  1  4.142113e-09  0.000064\n",
       "25   0.055  0.9   0.2       0  0.000085   27.310798  1  7.289389e-09  0.000085\n",
       "26   0.055  0.9   0.2     170  0.000086   41.751336  1  7.315196e-09  0.000086\n",
       "27   0.055  0.9   0.2    -145  0.000086  120.123256  1  7.333350e-09  0.000086\n",
       "28   0.055  0.9   0.2     120  0.000089  230.927125  1  7.879005e-09  0.000089\n",
       "29   0.055  0.9   0.2    -145  0.000106  163.499632  1  1.133312e-08  0.000106\n",
       "..     ...  ...   ...     ...       ...         ... ..           ...       ...\n",
       "420  0.040  0.9   1.0       0  0.000089   32.897147  1  7.870350e-09  0.000089\n",
       "421  0.040  0.9   1.0    -120  0.000107  353.422987  1  1.138856e-08  0.000107\n",
       "422  0.040  0.9   1.0     120  0.000107  341.755694  1  1.141850e-08  0.000107\n",
       "423  0.040  0.9   1.0     170  0.000107   64.353819  1  1.145992e-08  0.000107\n",
       "424  0.040  0.9   1.0     145  0.000107  232.870333  1  1.150845e-08  0.000107\n",
       "425  0.040  0.9   1.0       0  0.000111   44.207213  1  1.229666e-08  0.000111\n",
       "426  0.040  1.1   1.0    -120  0.000064  125.640429  1  4.130309e-09  0.000064\n",
       "427  0.040  1.1   1.0    -170  0.000064   32.503984  3  4.132255e-09  0.000064\n",
       "428  0.040  1.1   1.0     145  0.000064   79.623473  1  4.134416e-09  0.000064\n",
       "429  0.040  1.1   1.0       0  0.000064   24.772510  1  4.149972e-09  0.000064\n",
       "430  0.040  1.1   1.0    -145  0.000064   73.671811  3  4.128926e-09  0.000064\n",
       "431  0.040  1.1   1.0     170  0.000064   31.053093  1  4.145104e-09  0.000064\n",
       "432  0.040  1.1   1.0     170  0.000086   59.630639  1  7.338233e-09  0.000086\n",
       "433  0.040  1.1   1.0       0  0.000089   33.582872  1  7.855723e-09  0.000089\n",
       "434  0.040  1.1   1.0    -120  0.000107  348.252254  1  1.145096e-08  0.000107\n",
       "435  0.040  1.1   1.0     145  0.000107  193.133414  1  1.145959e-08  0.000107\n",
       "436  0.040  1.1   1.0     170  0.000107   83.673936  1  1.148272e-08  0.000107\n",
       "437  0.040  1.1   1.0       0  0.000111   44.107214  1  1.227780e-08  0.000111\n",
       "438  0.040  1.3   1.0     145  0.000064   88.547375  1  4.118679e-09  0.000064\n",
       "439  0.040  1.3   1.0    -170  0.000064   34.896203  3  4.117735e-09  0.000064\n",
       "440  0.040  1.3   1.0       0  0.000064   22.221646  1  4.125849e-09  0.000064\n",
       "441  0.040  1.3   1.0    -145  0.000064   65.665795  3  4.133758e-09  0.000064\n",
       "442  0.040  1.3   1.0     170  0.000064   33.332105  1  4.131471e-09  0.000064\n",
       "443  0.040  1.3   1.0    -120  0.000064  139.132259  1  4.148286e-09  0.000064\n",
       "444  0.040  1.3   1.0     170  0.000086   50.836832  1  7.313975e-09  0.000086\n",
       "445  0.040  1.3   1.0       0  0.000089   31.978572  1  7.859611e-09  0.000089\n",
       "446  0.040  1.3   1.0     145  0.000107  164.762425  1  1.141061e-08  0.000107\n",
       "447  0.040  1.3   1.0     170  0.000107   68.033342  1  1.146165e-08  0.000107\n",
       "448  0.040  1.3   1.0    -120  0.000107  325.643063  1  1.150694e-08  0.000107\n",
       "449  0.040  1.3   1.0       0  0.000111   42.002103  1  1.228353e-08  0.000111\n",
       "\n",
       "[450 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definimos nuestra variable OBJETIVO a predecir \"Diferencia de Presion\"\n",
    "y = df['P'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando el modelo\n",
    "Ahora vamos a buscar el modelo que mejor se ajuste a nuestro datos.\n",
    "\n",
    "Primero que nada vamos a dividir en TRAIN / VALIDATION para buscar el MODELO que mejor parezca que concuerde y finalmente un conjunto de TEST para ver como ese candidato modelo predice sobre un conjunto de datos que nunca vio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (450, 8)  y: (450,)\n",
      "X_train_val:  (360, 8)  y_train_val:  (360,)\n",
      "X_test:  (90, 8)  y_test:  (90,)\n"
     ]
    }
   ],
   "source": [
    "# División entre set de TRAIN+VALIDATION y TEST\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "print('X: ',X.shape,' y:', y.shape)\n",
    "print('X_train_val: ',X_train_val.shape, ' y_train_val: ',y_train_val.shape)\n",
    "print('X_test: ',X_test.shape, ' y_test: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar aqui el mayor problema es que no disponemos de muchas filas ... asi que \"si o si\" debemos realizar CROSS VALIDATION. Usaremos 10-Fold CRoss-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0] Linear Regression: score in TRAINING: 0.22 in TEST 0.23\n",
      "[fold 0] Ridge Regression: score in TRAINING: 0.01 in TEST -0.07\n",
      "[fold 0] Lasso Regression score in TRAINING: 0.01 in TEST -0.06\n",
      "[fold 0] KNeighborsRegressor score in TRAINING: 0.78 in TEST 0.50\n",
      "[fold 0] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.96\n",
      "[fold 0] RandomForestRegressor score in TRAINING: 1.00 in TEST 0.97\n",
      "[fold 0] GradientBoostingRegressor score in TRAINING: 0.98 in TEST 0.98\n",
      "[fold 1] Linear Regression: score in TRAINING: 0.23 in TEST 0.20\n",
      "[fold 1] Ridge Regression: score in TRAINING: 0.01 in TEST -0.01\n",
      "[fold 1] Lasso Regression score in TRAINING: 0.01 in TEST -0.01\n",
      "[fold 1] KNeighborsRegressor score in TRAINING: 0.76 in TEST 0.67\n",
      "[fold 1] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.97\n",
      "[fold 1] RandomForestRegressor score in TRAINING: 0.99 in TEST 0.97\n",
      "[fold 1] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.97\n",
      "[fold 2] Linear Regression: score in TRAINING: 0.25 in TEST -0.33\n",
      "[fold 2] Ridge Regression: score in TRAINING: 0.01 in TEST -0.17\n",
      "[fold 2] Lasso Regression score in TRAINING: 0.01 in TEST -0.19\n",
      "[fold 2] KNeighborsRegressor score in TRAINING: 0.77 in TEST 0.66\n",
      "[fold 2] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.96\n",
      "[fold 2] RandomForestRegressor score in TRAINING: 0.99 in TEST 0.95\n",
      "[fold 2] GradientBoostingRegressor score in TRAINING: 0.98 in TEST 0.96\n",
      "[fold 3] Linear Regression: score in TRAINING: 0.24 in TEST 0.06\n",
      "[fold 3] Ridge Regression: score in TRAINING: 0.01 in TEST -0.05\n",
      "[fold 3] Lasso Regression score in TRAINING: 0.01 in TEST -0.03\n",
      "[fold 3] KNeighborsRegressor score in TRAINING: 0.76 in TEST 0.64\n",
      "[fold 3] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.98\n",
      "[fold 3] RandomForestRegressor score in TRAINING: 1.00 in TEST 0.98\n",
      "[fold 3] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.97\n",
      "[fold 4] Linear Regression: score in TRAINING: 0.23 in TEST 0.18\n",
      "[fold 4] Ridge Regression: score in TRAINING: 0.01 in TEST -0.05\n",
      "[fold 4] Lasso Regression score in TRAINING: 0.01 in TEST -0.05\n",
      "[fold 4] KNeighborsRegressor score in TRAINING: 0.77 in TEST 0.66\n",
      "[fold 4] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.94\n",
      "[fold 4] RandomForestRegressor score in TRAINING: 0.99 in TEST 0.97\n",
      "[fold 4] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.98\n",
      "[fold 5] Linear Regression: score in TRAINING: 0.23 in TEST 0.22\n",
      "[fold 5] Ridge Regression: score in TRAINING: 0.01 in TEST -0.05\n",
      "[fold 5] Lasso Regression score in TRAINING: 0.01 in TEST -0.01\n",
      "[fold 5] KNeighborsRegressor score in TRAINING: 0.76 in TEST 0.61\n",
      "[fold 5] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.96\n",
      "[fold 5] RandomForestRegressor score in TRAINING: 1.00 in TEST 0.97\n",
      "[fold 5] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.98\n",
      "[fold 6] Linear Regression: score in TRAINING: 0.23 in TEST 0.10\n",
      "[fold 6] Ridge Regression: score in TRAINING: 0.01 in TEST -0.07\n",
      "[fold 6] Lasso Regression score in TRAINING: 0.01 in TEST -0.07\n",
      "[fold 6] KNeighborsRegressor score in TRAINING: 0.77 in TEST 0.52\n",
      "[fold 6] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.98\n",
      "[fold 6] RandomForestRegressor score in TRAINING: 0.99 in TEST 0.97\n",
      "[fold 6] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.97\n",
      "[fold 7] Linear Regression: score in TRAINING: 0.23 in TEST 0.18\n",
      "[fold 7] Ridge Regression: score in TRAINING: 0.01 in TEST 0.02\n",
      "[fold 7] Lasso Regression score in TRAINING: 0.00 in TEST 0.01\n",
      "[fold 7] KNeighborsRegressor score in TRAINING: 0.77 in TEST 0.69\n",
      "[fold 7] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.99\n",
      "[fold 7] RandomForestRegressor score in TRAINING: 1.00 in TEST 0.98\n",
      "[fold 7] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.98\n",
      "[fold 8] Linear Regression: score in TRAINING: 0.21 in TEST 0.34\n",
      "[fold 8] Ridge Regression: score in TRAINING: 0.01 in TEST -0.03\n",
      "[fold 8] Lasso Regression score in TRAINING: 0.01 in TEST -0.03\n",
      "[fold 8] KNeighborsRegressor score in TRAINING: 0.75 in TEST 0.66\n",
      "[fold 8] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.97\n",
      "[fold 8] RandomForestRegressor score in TRAINING: 1.00 in TEST 0.98\n",
      "[fold 8] GradientBoostingRegressor score in TRAINING: 0.98 in TEST 0.99\n",
      "[fold 9] Linear Regression: score in TRAINING: 0.22 in TEST 0.26\n",
      "[fold 9] Ridge Regression: score in TRAINING: 0.01 in TEST -0.00\n",
      "[fold 9] Lasso Regression score in TRAINING: 0.01 in TEST -0.01\n",
      "[fold 9] KNeighborsRegressor score in TRAINING: 0.76 in TEST 0.69\n",
      "[fold 9] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.94\n",
      "[fold 9] RandomForestRegressor score in TRAINING: 1.00 in TEST 0.96\n",
      "[fold 9] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.97\n",
      "\n",
      "\n",
      "Linear Regression avg(SCORE): 0.143416630163\n",
      "Ridge Regression avg(SCORE): -0.0478050646083\n",
      "Lasso Regression avg(SCORE): -0.0455023089295\n",
      "KNeighbors Regression avg(SCORE):  0.631048591978\n",
      "Decission Tree avg(SCORE) 0.964803935869\n",
      "Random Forest avg(SCORE) 0.971966365665\n",
      "Gradient Boosting avg(SCORE) 0.974397489638\n"
     ]
    }
   ],
   "source": [
    "# creamos las variables de score para guardar cada una de las ejecuciones\n",
    "score_lm = []\n",
    "score_rdg = []\n",
    "score_lss = []\n",
    "score_knn = []\n",
    "score_dt = []\n",
    "score_rf = []\n",
    "score_gb = []\n",
    "\n",
    "# Al disponer de pocas filas realizamos CROSS Validation \n",
    "# 10-Fold Cross-Validation            \n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "for k, (train, val)  in enumerate (kf.split(X_train_val)):\n",
    "\n",
    "    X_train, y_train, X_val, y_val = X[train], y[train], X[val], y[val]\n",
    "    \n",
    "    \n",
    "    # Linear Regression \n",
    "    lm = LinearRegression().fit(X_train, y_train)\n",
    "    \n",
    "    # Calculamos SCORE\n",
    "    score_training = lm.score(X_train, y_train)\n",
    "    score_val = lm.score(X_val, y_val)\n",
    "    \n",
    "    print(\"[fold {0}] Linear Regression: score in TRAINING: {1:.2f} in TEST {2:.2f}\".format(k, score_training, score_val))  \n",
    "    \n",
    "    # Guardamos el SCOREque nos ha dado en validacion para luego poder hacer la media\n",
    "    score_lm.append(score_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Ridge Regression \n",
    "    rdg = Ridge().fit(X_train, y_train)\n",
    "    \n",
    "    # Calculamos SCORE\n",
    "    score_training = rdg.score(X_train, y_train)\n",
    "    score_val = rdg.score(X_val, y_val)\n",
    "    \n",
    "    print(\"[fold {0}] Ridge Regression: score in TRAINING: {1:.2f} in TEST {2:.2f}\".format(k, score_training, score_val))  \n",
    "  \n",
    "    # Guardamos el SCOREque nos ha dado en validacion para luego poder hacer la media\n",
    "    score_rdg.append(score_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Lasso Regression \n",
    "    lss = Lasso().fit(X_train, y_train)\n",
    "    \n",
    "     # Calculamos SCORE\n",
    "    score_training = lss.score(X_train, y_train)\n",
    "    score_val = lss.score(X_val, y_val)\n",
    "    \n",
    "    print(\"[fold {0}] Lasso Regression score in TRAINING: {1:.2f} in TEST {2:.2f}\".format(k, score_training, score_val))  \n",
    "     \n",
    "    score_lss.append(score_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # KNeighborsRegressor Regression \n",
    "    knn = KNeighborsRegressor().fit(X_train, y_train)\n",
    "    \n",
    "     # Calculamos SCORE\n",
    "    score_training = knn.score(X_train, y_train)\n",
    "    score_val = knn.score(X_val, y_val)\n",
    "        \n",
    "    print(\"[fold {0}] KNeighborsRegressor score in TRAINING: {1:.2f} in TEST {2:.2f}\".format(k, score_training, score_val))  \n",
    "        \n",
    "    score_knn.append(score_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Arbol de decision        \n",
    "    dt = tree.DecisionTreeRegressor().fit(X_train, y_train)\n",
    "    \n",
    "    # Calculamos SCORE\n",
    "    score_training = dt.score(X_train, y_train)\n",
    "    score_val = dt.score(X_val, y_val)\n",
    "    \n",
    "    print(\"[fold {0}] DecisionTreeRegressor score in TRAINING: {1:.2f} in TEST {2:.2f}\".format(k, score_training, score_val))  \n",
    "       \n",
    "    score_dt.append(score_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Random Forest\n",
    "    rf = ensemble.RandomForestRegressor().fit(X_train, y_train)\n",
    "    \n",
    "    # Calculamos SCORE\n",
    "    score_training = rf.score(X_train, y_train)\n",
    "    score_val = rf.score(X_val, y_val)\n",
    "    \n",
    "    print(\"[fold {0}] RandomForestRegressor score in TRAINING: {1:.2f} in TEST {2:.2f}\".format(k, score_training, score_val))  \n",
    "\n",
    "    score_rf.append(score_val)\n",
    "    \n",
    "    \n",
    "    # Gradient Boosting\n",
    "    gb = ensemble.GradientBoostingRegressor().fit(X_train, y_train)\n",
    "    \n",
    "     # Calculamos SCORE\n",
    "    score_training = gb.score(X_train, y_train)\n",
    "    score_val = gb.score(X_val, y_val)\n",
    " \n",
    "    print(\"[fold {0}] GradientBoostingRegressor score in TRAINING: {1:.2f} in TEST {2:.2f}\".format(k, score_training, score_val))  \n",
    "\n",
    "    score_gb.append(score_val)\n",
    "          \n",
    "        \n",
    "# Una vez ya entrenados los distintos modelos y realizado el CROSS VALIDATION, mostramos las medias de sus SCORES\n",
    "print('\\n')\n",
    "\n",
    "print('Linear Regression avg(SCORE):',np.mean(score_lm))\n",
    "print('Ridge Regression avg(SCORE):',np.mean(score_rdg))\n",
    "print('Lasso Regression avg(SCORE):',np.mean(score_lss))\n",
    "print('KNeighbors Regression avg(SCORE): ',np.mean(score_knn))\n",
    "print('Decission Tree avg(SCORE)',np.mean(score_dt))\n",
    "print('Random Forest avg(SCORE)',np.mean(score_rf))\n",
    "print('Gradient Boosting avg(SCORE)',np.mean(score_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los scores anteriores ya vemos que ningun modelo lineal es representativo de los datos que estamos buscando  y que necesitamos trabjar con modelos mas complejos.\n",
    "\n",
    "Nos vamos por tanto a decantar a buscar hyperparametros tanto para Decission Tree, Random Forest como Gradient Boosting.\n",
    "\n",
    "A priori tanto Random Forest como Gradient Boosting parecen un pelin mejor que Decisstion Tree pero ... también hay que tener en cuenta que computacionalmente requieren más tiempo para realizar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor: 0.97 params  {'max_depth': 7, 'max_features': None}\n",
      "RandomForestRegressor: 0.98 params  {'max_depth': 7, 'max_features': None, 'n_estimators': 500}\n",
      "GradientBoostingRegressor: 0.98 params  {'max_depth': 8, 'max_features': None, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# División entre set de TRAIN+VALIDATION y TEST\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "parametros_modelo = {\n",
    "    'max_depth': list(range(3, 10 + 1)),\n",
    "    'max_features': [None, 'log2', 'sqrt'],\n",
    "}\n",
    "\n",
    "\n",
    "# DecisionTreeRegressor        \n",
    "dt = tree.DecisionTreeRegressor()\n",
    "grid_search = GridSearchCV(dt, parametros_modelo,  cv = 10).fit(X_train, y_train)\n",
    "\n",
    "# Mejores parametros para el modelo\n",
    "print(\"DecisionTreeRegressor: {0:.2f} params  {1}\".format(grid_search.best_score_, grid_search.best_params_))\n",
    "\n",
    "\n",
    "parametros_modelo = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200, 500, 1000],\n",
    "    'max_depth': list(range(3, 10 + 1)),\n",
    "    'max_features': [None, 'log2', 'sqrt'],\n",
    "}\n",
    "\n",
    "# RandomForestRegressor\n",
    "rf = ensemble.RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf, parametros_modelo,  cv = 10).fit(X_train, y_train)\n",
    "\n",
    "# Mejores parametros para el modelo\n",
    "print(\"RandomForestRegressor: {0:.2f} params  {1}\".format(grid_search.best_score_, grid_search.best_params_))\n",
    "      \n",
    "\n",
    "parametros_modelo = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200, 500, 1000],\n",
    "    'max_depth': list(range(3, 10 + 1)),\n",
    "    'max_features': [None, 'log2', 'sqrt'],\n",
    "}\n",
    "\n",
    "# GradientBoostingRegressor\n",
    "gb = ensemble.GradientBoostingRegressor()\n",
    "grid_search = GridSearchCV(rf, parametros_modelo,  cv = 10).fit(X_train, y_train)\n",
    "\n",
    "# Mejores parametros para el modelo\n",
    "print(\"GradientBoostingRegressor: {0:.2f} params  {1}\".format(grid_search.best_score_, grid_search.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente ya vemos que mejor sigue estando entre RandomForestRegressor / GradientBoostingRegressor y que sus parámetros más óptimos para los que ha sido entrenado el modelo es:\n",
    "    \n",
    "RandomForestRegressor: 0.98 params  {'max_depth': 7, 'max_features': None, 'n_estimators': 500}\n",
    "GradientBoostingRegressor: 0.98 params  {'max_depth': 8, 'max_features': None, 'n_estimators': 200}\n",
    "\n",
    "Consideramos que siendo RandomForestRegressor más facil de entrenar seria realmente nuestro modelo final.\n",
    "\n",
    "Ahora vamos a ejecutar este modelo, para el conjunto de TEST y ya podremos ver con certeza cual es realmente el SCORE arrojado.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96831636403781063, 228.09162606909919, 9.6927881248549124)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos el R², el MSE y el MAE.\n",
    "\n",
    "reg = ensemble.RandomForestRegressor(\n",
    "    max_depth=7, n_estimators=500\n",
    ").fit(X_train_val, y_train_val)\n",
    "\n",
    "pred = reg.predict(X_test)\n",
    "(\n",
    "    reg.score(X_test, y_test), # R²\n",
    "    metrics.mean_squared_error(y_test, pred), # MSE\n",
    "    metrics.mean_absolute_error(y_test, pred) # MAE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones del TFM\n",
    "\n",
    "El TFM ha sido una buena forma de poner en práctica muchas de las herramientas aprendidas durante el curso, sobretodo el modelaje de datos que es en lo que se ha centrado este TFM ya que considero una de las partes más interesantes del Master.\n",
    "\n",
    "Efectivamente he podido comprobar que la obtención de los datos es siempre muy costosa. En mi caso preparar las simulaciones y lanzarlas al cluster para luego moverlas siendo archivos tan grandes ha sido un trabajo muy tedioso, ya que las simulaciones llegaban a tardar horas, dependiendo de la calidad del mallado.\n",
    "\n",
    "Por otro lado la limpieza de datos ha sido muy importante al igual que el chequeo de los datos, ya que  muchas simulaciones o no acababan bien o arrojaban datos que no eran coherentes o bien encontraban errores humanos de lanzar varios casos mas de una vez.\n",
    "\n",
    "Como target del TFM creo que se ha conseguido alcanzar, ya que se ha conseguido encontrar un modelo que realmente indentifica los datos, en el fondo ya sabiammos que existia un modelo de fisica de fluidos que lo calculabam pero ... ¿Podia un modelo de machine learning encontrar el en \"en si de los datos\", sin saber de fisica de fluidos?\n",
    "\n",
    "Bueno pues parece que si ... con una certeza del 96%\n\n",
    "Otros de los objetivos del TFM que me gustaría remarcar es que la utilización de este modelo por parte del doctor es en la propia consulta y de forma inmediata una vez que el modelo esta entrenado, por tanto tiene la ventaja respecto a la simulación que no debe ser externalizado el proceso a un centro de investigación y que por supuesto tampoco requiere conocimientos ni de segmentación ni de mallado con elementos finitos.",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

