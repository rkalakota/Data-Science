{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias ...\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import ensemble\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model.ridge import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "import warnings\n",
    "import math\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de datos archivo CSV\n",
    "df = pd.read_csv('C:\\\\JSONFINAL\\\\salida.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Check Data\n",
    "\n",
    "Aqui partiendo del Jupyter Notebook 0.Analisis_Exploratorio_Datos vamos aplicar algunas conclusiones tanto de limpieza como de validacion de datos, para asi detectar valores anómalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminacion de filas repetidas\n",
    "df = df.groupby(['Caso X', 'D','L','Beta','Velocidad','Angulo','A','B','Q', 'Reynolds','TotalAreaInlet', 'P']).size().reset_index()\n",
    "\n",
    "# Eliminacion de filas que tienen un coeficiente de Reynols muy negativo. Posiblemente a simulaciones que han producido un error.\n",
    "# xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "\n",
    "# Eliminacion de columnas A y B, por ser variables que son de salida de la simulacion\n",
    "X = df.drop(['A','B'], axis=1, inplace=True)\n",
    "\n",
    "# Eliminacion de la variable categorica Caso X, al ser una variable que no aporta nada, ya que tan solo define dado un caso\n",
    "# a un conjunto de caracteristicas geometricas D,L,Beta\n",
    "X = df.drop(['Caso X'],axis=1, inplace=True)\n",
    "\n",
    "# Eliminacion de la columna Reynolds, al saber que existe una relacion y Q\n",
    "X = df.drop(['Reynolds'], axis=1, inplace=True)\n",
    "\n",
    "# Eliminacion de la columna TotalAreaInlet, al saber que existe una relacion y Q\n",
    "X = df.drop(['TotalAreaInlet'], axis=1, inplace=True)\n",
    "\n",
    "# Eliminacion de la columna Velocidad, al saber que existe una relacion y Q\n",
    "X = df.drop(['Velocidad'], axis=1, inplace=True)\n",
    "\n",
    "# Featuring Engineering\n",
    "df['Q'] = abs(df['Q'])\n",
    "df['QQ'] = df['Q'] * df['Q']\n",
    "df['QPlusQQ'] = df['Q'] + (df['Q'] * df['Q'])\n",
    "\n",
    "# Por supuesto quitamos como variable de entrada la variable a PREDECIR, pero no inplace porque luego se lo asignaremos a Y\n",
    "X = df.drop(['P'], axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>L</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Angulo</th>\n",
       "      <th>Q</th>\n",
       "      <th>P</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>19.252066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>24.926916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>82.646603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>30.105155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-120</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>116.412337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>82.088580</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>119.307336</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>27.382207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>40.487631</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>128.531086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-170</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>41.901642</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>233.041292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>36.227969</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>51.421813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>193.705257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-170</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>56.822894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>213.989580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>283.501946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>119.507168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>19.334154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>26.701303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>27.946233</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-120</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>125.712072</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>92.636307</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>74.348635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>27.310798</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>41.751336</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>120.123256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>230.927125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>163.499632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>32.897147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-120</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>353.422987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>341.755694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>64.353819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>232.870333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>44.207213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-120</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>125.640429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>32.503984</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>79.623473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>24.772510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>73.671811</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>31.053093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>59.630639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>33.582872</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-120</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>348.252254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>193.133414</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>83.673936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>44.107214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>88.547375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>34.896203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>22.221646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-145</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>65.665795</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>33.332105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-120</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>139.132259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>50.836832</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>31.978572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>164.762425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>68.033342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-120</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>325.643063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0.040</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>42.002103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         D    L  Beta  Angulo         Q           P  0\n",
       "0    0.040  0.9   0.2       0  0.000064   19.252066  1\n",
       "1    0.040  0.9   0.2     170  0.000064   24.926916  1\n",
       "2    0.040  0.9   0.2    -145  0.000064   82.646603  1\n",
       "3    0.040  0.9   0.2    -170  0.000064   30.105155  1\n",
       "4    0.040  0.9   0.2    -120  0.000064  116.412337  1\n",
       "5    0.040  0.9   0.2     145  0.000064   82.088580  2\n",
       "6    0.040  0.9   0.2     120  0.000067  119.307336  1\n",
       "7    0.040  0.9   0.2       0  0.000085   27.382207  1\n",
       "8    0.040  0.9   0.2     170  0.000085   40.487631  1\n",
       "9    0.040  0.9   0.2    -145  0.000085  128.531086  1\n",
       "10   0.040  0.9   0.2    -170  0.000086   41.901642  1\n",
       "11   0.040  0.9   0.2     120  0.000089  233.041292  1\n",
       "12   0.040  0.9   0.2       0  0.000107   36.227969  2\n",
       "13   0.040  0.9   0.2     170  0.000107   51.421813  1\n",
       "14   0.040  0.9   0.2    -145  0.000107  193.705257  1\n",
       "15   0.040  0.9   0.2    -170  0.000107   56.822894  1\n",
       "16   0.040  0.9   0.2     145  0.000107  213.989580  1\n",
       "17   0.040  0.9   0.2     120  0.000111  283.501946  1\n",
       "18   0.055  0.9   0.2     120  0.000064  119.507168  1\n",
       "19   0.055  0.9   0.2       0  0.000064   19.334154  1\n",
       "20   0.055  0.9   0.2    -170  0.000064   26.701303  1\n",
       "21   0.055  0.9   0.2     170  0.000064   27.946233  2\n",
       "22   0.055  0.9   0.2    -120  0.000064  125.712072  3\n",
       "23   0.055  0.9   0.2     145  0.000064   92.636307  2\n",
       "24   0.055  0.9   0.2    -145  0.000064   74.348635  1\n",
       "25   0.055  0.9   0.2       0  0.000085   27.310798  1\n",
       "26   0.055  0.9   0.2     170  0.000086   41.751336  1\n",
       "27   0.055  0.9   0.2    -145  0.000086  120.123256  1\n",
       "28   0.055  0.9   0.2     120  0.000089  230.927125  1\n",
       "29   0.055  0.9   0.2    -145  0.000106  163.499632  1\n",
       "..     ...  ...   ...     ...       ...         ... ..\n",
       "420  0.040  0.9   1.0       0  0.000089   32.897147  1\n",
       "421  0.040  0.9   1.0    -120  0.000107  353.422987  1\n",
       "422  0.040  0.9   1.0     120  0.000107  341.755694  1\n",
       "423  0.040  0.9   1.0     170  0.000107   64.353819  1\n",
       "424  0.040  0.9   1.0     145  0.000107  232.870333  1\n",
       "425  0.040  0.9   1.0       0  0.000111   44.207213  1\n",
       "426  0.040  1.1   1.0    -120  0.000064  125.640429  1\n",
       "427  0.040  1.1   1.0    -170  0.000064   32.503984  3\n",
       "428  0.040  1.1   1.0     145  0.000064   79.623473  1\n",
       "429  0.040  1.1   1.0       0  0.000064   24.772510  1\n",
       "430  0.040  1.1   1.0    -145  0.000064   73.671811  3\n",
       "431  0.040  1.1   1.0     170  0.000064   31.053093  1\n",
       "432  0.040  1.1   1.0     170  0.000086   59.630639  1\n",
       "433  0.040  1.1   1.0       0  0.000089   33.582872  1\n",
       "434  0.040  1.1   1.0    -120  0.000107  348.252254  1\n",
       "435  0.040  1.1   1.0     145  0.000107  193.133414  1\n",
       "436  0.040  1.1   1.0     170  0.000107   83.673936  1\n",
       "437  0.040  1.1   1.0       0  0.000111   44.107214  1\n",
       "438  0.040  1.3   1.0     145  0.000064   88.547375  1\n",
       "439  0.040  1.3   1.0    -170  0.000064   34.896203  3\n",
       "440  0.040  1.3   1.0       0  0.000064   22.221646  1\n",
       "441  0.040  1.3   1.0    -145  0.000064   65.665795  3\n",
       "442  0.040  1.3   1.0     170  0.000064   33.332105  1\n",
       "443  0.040  1.3   1.0    -120  0.000064  139.132259  1\n",
       "444  0.040  1.3   1.0     170  0.000086   50.836832  1\n",
       "445  0.040  1.3   1.0       0  0.000089   31.978572  1\n",
       "446  0.040  1.3   1.0     145  0.000107  164.762425  1\n",
       "447  0.040  1.3   1.0     170  0.000107   68.033342  1\n",
       "448  0.040  1.3   1.0    -120  0.000107  325.643063  1\n",
       "449  0.040  1.3   1.0       0  0.000111   42.002103  1\n",
       "\n",
       "[450 rows x 7 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos nuestra variable OBJETIVO a predecir \"Diferencia de Presion\"\n",
    "y = df['P'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando el modelo\n",
    "Ahora vamos a buscar el modelo que mejor se ajuste a nuestro datos.\n",
    "\n",
    "Primero que nada vamos a dividir en TRAIN / VALIDATION para buscar el MODELO que mejor parezca que concuerde y finalmente un conjunto de TEST para ver como ese candidato modelo predice sobre un conjunto de datos que nunca vio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X: ', (450L, 8L), ' y:', (450L,))\n",
      "('X_train_val: ', (360L, 8L), ' y_train_val: ', (360L,))\n",
      "('X_test: ', (90L, 8L), ' y_test: ', (90L,))\n"
     ]
    }
   ],
   "source": [
    "# División entre set de TRAIN+VALIDATION y TEST\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "print('X: ',X.shape,' y:', y.shape)\n",
    "print('X_train_val: ',X_train_val.shape, ' y_train_val: ',y_train_val.shape)\n",
    "print('X_test: ',X_test.shape, ' y_test: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar aqui el mayor problema es que no disponemos de muchas filas ... asi que \"si o si\" debemos realizar CROSS VALIDATION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0] Linear Regression: score in TRAINING: 0.24 in TEST -0.10\n",
      "[fold 0] Ridge Regression: score in TRAINING: 0.01 in TEST -0.20\n",
      "[fold 0] Lasso Regression score in TRAINING: 0.01 in TEST -0.18\n",
      "[fold 0] KNeighborsRegressor score in TRAINING: 0.76 in TEST 0.69\n",
      "[fold 0] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.97\n",
      "[fold 0] RandomForestRegressor score in TRAINING: 0.99 in TEST 0.97\n",
      "[fold 0] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.98\n",
      "[fold 1] Linear Regression: score in TRAINING: 0.23 in TEST 0.17\n",
      "[fold 1] Ridge Regression: score in TRAINING: 0.01 in TEST -0.02\n",
      "[fold 1] Lasso Regression score in TRAINING: 0.01 in TEST -0.02\n",
      "[fold 1] KNeighborsRegressor score in TRAINING: 0.77 in TEST 0.59\n",
      "[fold 1] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.94\n",
      "[fold 1] RandomForestRegressor score in TRAINING: 1.00 in TEST 0.95\n",
      "[fold 1] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.95\n",
      "[fold 2] Linear Regression: score in TRAINING: 0.23 in TEST 0.24\n",
      "[fold 2] Ridge Regression: score in TRAINING: 0.01 in TEST 0.02\n",
      "[fold 2] Lasso Regression score in TRAINING: 0.01 in TEST 0.01\n",
      "[fold 2] KNeighborsRegressor score in TRAINING: 0.77 in TEST 0.47\n",
      "[fold 2] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.98\n",
      "[fold 2] RandomForestRegressor score in TRAINING: 1.00 in TEST 0.97\n",
      "[fold 2] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.97\n",
      "[fold 3] Linear Regression: score in TRAINING: 0.22 in TEST 0.17\n",
      "[fold 3] Ridge Regression: score in TRAINING: 0.01 in TEST -0.13\n",
      "[fold 3] Lasso Regression score in TRAINING: 0.01 in TEST -0.13\n",
      "[fold 3] KNeighborsRegressor score in TRAINING: 0.75 in TEST 0.67\n",
      "[fold 3] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.98\n",
      "[fold 3] RandomForestRegressor score in TRAINING: 1.00 in TEST 0.99\n",
      "[fold 3] GradientBoostingRegressor score in TRAINING: 0.98 in TEST 0.97\n",
      "[fold 4] Linear Regression: score in TRAINING: 0.24 in TEST 0.11\n",
      "[fold 4] Ridge Regression: score in TRAINING: 0.01 in TEST -0.02\n",
      "[fold 4] Lasso Regression score in TRAINING: 0.01 in TEST 0.00\n",
      "[fold 4] KNeighborsRegressor score in TRAINING: 0.75 in TEST 0.62\n",
      "[fold 4] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.97\n",
      "[fold 4] RandomForestRegressor score in TRAINING: 0.99 in TEST 0.98\n",
      "[fold 4] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.98\n",
      "[fold 5] Linear Regression: score in TRAINING: 0.24 in TEST 0.03\n",
      "[fold 5] Ridge Regression: score in TRAINING: 0.01 in TEST -0.06\n",
      "[fold 5] Lasso Regression score in TRAINING: 0.01 in TEST -0.04\n",
      "[fold 5] KNeighborsRegressor score in TRAINING: 0.76 in TEST 0.61\n",
      "[fold 5] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.98\n",
      "[fold 5] RandomForestRegressor score in TRAINING: 1.00 in TEST 0.98\n",
      "[fold 5] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.98\n",
      "[fold 6] Linear Regression: score in TRAINING: 0.23 in TEST 0.18\n",
      "[fold 6] Ridge Regression: score in TRAINING: 0.01 in TEST -0.00\n",
      "[fold 6] Lasso Regression score in TRAINING: 0.01 in TEST -0.01\n",
      "[fold 6] KNeighborsRegressor score in TRAINING: 0.77 in TEST 0.69\n",
      "[fold 6] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.96\n",
      "[fold 6] RandomForestRegressor score in TRAINING: 1.00 in TEST 0.96\n",
      "[fold 6] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.98\n",
      "[fold 7] Linear Regression: score in TRAINING: 0.21 in TEST 0.29\n",
      "[fold 7] Ridge Regression: score in TRAINING: 0.01 in TEST -0.09\n",
      "[fold 7] Lasso Regression score in TRAINING: 0.01 in TEST -0.09\n",
      "[fold 7] KNeighborsRegressor score in TRAINING: 0.75 in TEST 0.58\n",
      "[fold 7] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.95\n",
      "[fold 7] RandomForestRegressor score in TRAINING: 1.00 in TEST 0.97\n",
      "[fold 7] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.97\n",
      "[fold 8] Linear Regression: score in TRAINING: 0.22 in TEST 0.22\n",
      "[fold 8] Ridge Regression: score in TRAINING: 0.02 in TEST -0.06\n",
      "[fold 8] Lasso Regression score in TRAINING: 0.01 in TEST -0.03\n",
      "[fold 8] KNeighborsRegressor score in TRAINING: 0.76 in TEST 0.72\n",
      "[fold 8] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.96\n",
      "[fold 8] RandomForestRegressor score in TRAINING: 0.99 in TEST 0.96\n",
      "[fold 8] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.98\n",
      "[fold 9] Linear Regression: score in TRAINING: 0.23 in TEST 0.18\n",
      "[fold 9] Ridge Regression: score in TRAINING: 0.01 in TEST -0.03\n",
      "[fold 9] Lasso Regression score in TRAINING: 0.01 in TEST -0.02\n",
      "[fold 9] KNeighborsRegressor score in TRAINING: 0.77 in TEST 0.51\n",
      "[fold 9] DecisionTreeRegressor score in TRAINING: 1.00 in TEST 0.97\n",
      "[fold 9] RandomForestRegressor score in TRAINING: 1.00 in TEST 0.98\n",
      "[fold 9] GradientBoostingRegressor score in TRAINING: 0.99 in TEST 0.98\n",
      "\n",
      "\n",
      "('Linear Regression avg(SCORE):', 0.15021200625405706)\n",
      "('Ridge Regression avg(SCORE):', -0.05910035791118612)\n",
      "('Lasso Regression avg(SCORE):', -0.05145425650538158)\n",
      "('KNeighbors Regression avg(SCORE): ', 0.6131337168580415)\n",
      "('Decission Tree avg(SCORE)', 0.9651233847637061)\n",
      "('Random Forest avg(SCORE)', 0.9707023459439441)\n",
      "('Gradient Boosting avg(SCORE)', 0.9753156441924906)\n"
     ]
    }
   ],
   "source": [
    "# creamos las variables de score para guardar cada una de las ejecuciones\n",
    "score_lm = []\n",
    "score_rdg = []\n",
    "score_lss = []\n",
    "score_knn = []\n",
    "score_dt = []\n",
    "score_rf = []\n",
    "score_gb = []\n",
    "\n",
    "# Al disponer de pocas filas realizamos CROSS Validation \n",
    "# 10-Fold Cross-Validation            \n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "for k, (train, val)  in enumerate (kf.split(X_train_val)):\n",
    "\n",
    "    X_train, y_train, X_val, y_val = X[train], y[train], X[val], y[val]\n",
    "    \n",
    "    \n",
    "    # Linear Regression \n",
    "    lm = LinearRegression().fit(X_train, y_train)\n",
    "    \n",
    "    # Calculamos SCORE\n",
    "    score_training = lm.score(X_train, y_train)\n",
    "    score_val = lm.score(X_val, y_val)\n",
    "    \n",
    "    print(\"[fold {0}] Linear Regression: score in TRAINING: {1:.2f} in TEST {2:.2f}\".format(k, score_training, score_val))  \n",
    "    \n",
    "    # Guardamos el SCOREque nos ha dado en validacion para luego poder hacer la media\n",
    "    score_lm.append(score_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Ridge Regression \n",
    "    rdg = Ridge().fit(X_train, y_train)\n",
    "    \n",
    "    # Calculamos SCORE\n",
    "    score_training = rdg.score(X_train, y_train)\n",
    "    score_val = rdg.score(X_val, y_val)\n",
    "    \n",
    "    print(\"[fold {0}] Ridge Regression: score in TRAINING: {1:.2f} in TEST {2:.2f}\".format(k, score_training, score_val))  \n",
    "  \n",
    "    # Guardamos el SCOREque nos ha dado en validacion para luego poder hacer la media\n",
    "    score_rdg.append(score_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Lasso Regression \n",
    "    lss = Lasso().fit(X_train, y_train)\n",
    "    \n",
    "     # Calculamos SCORE\n",
    "    score_training = lss.score(X_train, y_train)\n",
    "    score_val = lss.score(X_val, y_val)\n",
    "    \n",
    "    print(\"[fold {0}] Lasso Regression score in TRAINING: {1:.2f} in TEST {2:.2f}\".format(k, score_training, score_val))  \n",
    "     \n",
    "    score_lss.append(score_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # KNeighborsRegressor Regression \n",
    "    knn = KNeighborsRegressor().fit(X_train, y_train)\n",
    "    \n",
    "     # Calculamos SCORE\n",
    "    score_training = knn.score(X_train, y_train)\n",
    "    score_val = knn.score(X_val, y_val)\n",
    "        \n",
    "    print(\"[fold {0}] KNeighborsRegressor score in TRAINING: {1:.2f} in TEST {2:.2f}\".format(k, score_training, score_val))  \n",
    "        \n",
    "    score_knn.append(score_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Arbol de decision        \n",
    "    dt = tree.DecisionTreeRegressor().fit(X_train, y_train)\n",
    "    \n",
    "    # Calculamos SCORE\n",
    "    score_training = dt.score(X_train, y_train)\n",
    "    score_val = dt.score(X_val, y_val)\n",
    "    \n",
    "    print(\"[fold {0}] DecisionTreeRegressor score in TRAINING: {1:.2f} in TEST {2:.2f}\".format(k, score_training, score_val))  \n",
    "       \n",
    "    score_dt.append(score_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Random Forest\n",
    "    rf = ensemble.RandomForestRegressor().fit(X_train, y_train)\n",
    "    \n",
    "    # Calculamos SCORE\n",
    "    score_training = rf.score(X_train, y_train)\n",
    "    score_val = rf.score(X_val, y_val)\n",
    "    \n",
    "    print(\"[fold {0}] RandomForestRegressor score in TRAINING: {1:.2f} in TEST {2:.2f}\".format(k, score_training, score_val))  \n",
    "\n",
    "    score_rf.append(score_val)\n",
    "    \n",
    "    \n",
    "    # Gradient Boosting\n",
    "    gb = ensemble.GradientBoostingRegressor().fit(X_train, y_train)\n",
    "    \n",
    "     # Calculamos SCORE\n",
    "    score_training = gb.score(X_train, y_train)\n",
    "    score_val = gb.score(X_val, y_val)\n",
    " \n",
    "    print(\"[fold {0}] GradientBoostingRegressor score in TRAINING: {1:.2f} in TEST {2:.2f}\".format(k, score_training, score_val))  \n",
    "\n",
    "    score_gb.append(score_val)\n",
    "          \n",
    "        \n",
    "# Una vez ya entrenados los distintos modelos y realizado el CROSS VALIDATION, mostramos las medias de sus SCORES\n",
    "print('\\n')\n",
    "\n",
    "print('Linear Regression avg(SCORE):',np.mean(score_lm))\n",
    "print('Ridge Regression avg(SCORE):',np.mean(score_rdg))\n",
    "print('Lasso Regression avg(SCORE):',np.mean(score_lss))\n",
    "print('KNeighbors Regression avg(SCORE): ',np.mean(score_knn))\n",
    "print('Decission Tree avg(SCORE)',np.mean(score_dt))\n",
    "print('Random Forest avg(SCORE)',np.mean(score_rf))\n",
    "print('Gradient Boosting avg(SCORE)',np.mean(score_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los scores anteriores ya vemos que ningun modelo lineal es representativo de los datos que estamos buscando  y que necesitamos trabjar con modelos mas complejos.\n",
    "\n",
    "Nos vamos por tanto a decantar a buscar hyperparametros tanto para Decission Tree, Random Forest como Gradient Boosting.\n",
    "\n",
    "A priori Gradient Boosting parece un pelin mejor pero ... también hay que tener en cuenta que computacionalmente requiere más tiempo para realizar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor: 0.95 params  {}\n",
      "RandomForestRegressor: 0.97 params  {'max_features': None, 'n_estimators': 10, 'max_depth': 7}\n",
      "RandomForestRegressor: 0.97 params  {'max_features': None, 'n_estimators': 1000, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "# División entre set de TRAIN+VALIDATION y TEST\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "parametros_modelo = {\n",
    "    'max_depth': list(range(3, 10 + 1)),\n",
    "    'max_features': [None, 'log2', 'sqrt'],\n",
    "}\n",
    "\n",
    "\n",
    "# DecisionTreeRegressor        \n",
    "dt = tree.DecisionTreeRegressor()\n",
    "grid_search = GridSearchCV(dt, parametros_modelo,  cv = 10).fit(X_train, y_train)\n",
    "\n",
    "# Mejores parametros para el modelo\n",
    "print(\"DecisionTreeRegressor: {0:.2f} params  {1}\".format(grid_search.best_score_, grid_search.best_params_))\n",
    "\n",
    "\n",
    "parametros_modelo = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200, 500, 1000],\n",
    "    'max_depth': list(range(3, 10 + 1)),\n",
    "    'max_features': [None, 'log2', 'sqrt'],\n",
    "}\n",
    "\n",
    "# RandomForestRegressor\n",
    "rf = ensemble.RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf, parametros_modelo,  cv = 10).fit(X_train, y_train)\n",
    "\n",
    "# Mejores parametros para el modelo\n",
    "print(\"RandomForestRegressor: {0:.2f} params  {1}\".format(grid_search.best_score_, grid_search.best_params_))\n",
    "      \n",
    "\n",
    "parametros_modelo = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200, 500, 1000],\n",
    "    'max_depth': list(range(3, 10 + 1)),\n",
    "    'max_features': [None, 'log2', 'sqrt'],\n",
    "}\n",
    "\n",
    "# GradientBoostingRegressor\n",
    "gb = ensemble.GradientBoostingRegressor()\n",
    "grid_search = GridSearchCV(rf, parametros_modelo,  cv = 10).fit(X_train, y_train)\n",
    "\n",
    "# Mejores parametros para el modelo\n",
    "print(\"GradientBoostingRegressor: {0:.2f} params  {1}\".format(grid_search.best_score_, grid_search.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente ya vemos que el mejor modelo es el GradientBoostingRegressor y que sus parámetros más óptimos para los que ha sido entrenado el modelo es:\n",
    "    \n",
    "Ahora vamos a ejecutar este modelo, para el conjunto de TEST y ya podremos ver con certeza cual es realmente el SCORE arrojado.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9791432491231095, 148.2732078320623, 8.557495533206053)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos el R², el MSE y el MAE.\n",
    "\n",
    "reg = ensemble.RandomForestRegressor(\n",
    "    max_depth=7, n_estimators=10\n",
    ").fit(X_train_val, y_train_val)\n",
    "\n",
    "pred = reg.predict(X_test)\n",
    "(\n",
    "    reg.score(X_test, y_test), # R²\n",
    "    metrics.mean_squared_error(y_test, pred), # MSE\n",
    "    metrics.mean_absolute_error(y_test, pred) # MAE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
